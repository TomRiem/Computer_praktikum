\chapter{Introduction}

In the past decades, a notable interest has grown for the problem of minimizing a smooth objective function $f$ on a Riemannian manifold, which offers efficient alternative formulations to many problems. The applications are many and varied, they occur in engineering and science, which include the following fields: algorithmic questions pertaining to linear algebra, signal processing, data mining, statistical image analysis, financial mathematics, nanostructures, model reduction of dynamical systems and more. Optimization on Riemannian manifolds, also called Riemannian optimization, concerns finding an optimum of a real-valued function $f$ defined over a manifold. It can be thought of as unconstrained optimization on a constrained space. As such, optimization algorithms on manifolds are not fundamentally different from classical algorithms for unconstrained optimization in $\mathbb{R}^n$. On an Euclidean space, various methods of solving unconstrained optimization problems are known. The concepts of these algorithms can be used for the Riemannian optimization if many definitions are reconsidered. This reconsideration is crucial because the ideas are not extended simply from the Euclidean setup. The book \cite{AbsilMahonySepulchre:2008} provides a comprehensive introduction to this area, with an emphasis on providing the necessary background in differential geometry instrumental to algorithmic development. \\
Many manifold-based algorithms have been proposed or are under development. The reason for this is that they bring significant benefits, such as that all the iterates stay on the manifold, i.e., they satisfy the constraints (this property allows us to stop the iteration early), that they have the convergence properties of unconstrained optimization algorithms while operating on a constrained set, that there is no need to consider Lagrange multipliers or penalty functions and more \cite[p.~2-3]{Huang:2013}. The idea of quasi-Newton methods on Riemannian manifolds is also not new. The first research paper to focus this topic was \cite{Gabay:1982}, but it was barely noticed. Nevertheless, a generalization of quasi-Newton methods in general and the BFGS method in particular is becoming more and more popular, since the many positive properties can be transferred to the Riemannian setting. In the Euclidean setting, the BFGS method is a well-known quasi-Newton method that has been viewed for many years as the best quasi-Newton method for solving unconstrained optimization problems, therefore much attention has been paid to generalizing this method to Riemannian manifolds. \\
This thesis is intended to deal with the BFGS method on Riemannian manifolds. We are interested in whether, and above all, how the BFGS method can be generalized for the application on Riemannian manifolds. We want to summarize the currently known Riemannian BFGS methods. Their core aspects should be discussed and their convergence results should be presented. Furthermore, we are interested in how a BFGS method on Riemannian manifolds can be implemented efficiently and which requirements have to be taken into account. An implementation of such a method should happen and its performance should be compared with results of other BFGS methods on Riemannian manifolds. \\
The thesis is organized as follows: We first establish some preliminary concepts in \cref{Section2.1} and then describe the Euclidean quasi-Newton methods in \cref{Section2.2}. With these previously described structures we derive the BFGS formula in \cref{Section2.3} and discuss its characteristics. In \cref{Section2.4} we present the Euclidean BFGS method, discuss key characteristics and present convergence properties of it. Since we are interested in global convergence for a larger class of functions, we introduce the so-called cautious BFGS method from \cite{LiFukushima:2001} in \cref{Section2.5}. In \cref{Section2.6} we introduce the limited-memory BFGS method, which offers storage advantages in practice. \\
Basics about differential geometry, Riemannian manifolds, the Riemannian metric and other important implications, which are needed to derive the BFGS method on Riemannian manifolds, are discussed in \cref{Chapter3}. \\
We first establish some preliminary concepts for the BFGS method and quasi-Newton methods in general on Riemannian manifolds in \cref{Section4.1}. The characteristics which define quasi-Newton methods on Riemannian manifolds, and how they work, is presented in \cref{Section4.2}. In \cref{Section4.3} we derive the Riemannian BFGS formula for operators on tangent spaces and discuss its characteristics. We present in \cref{Section4.4} the general Riemannian BFGS method, the method from \cite{Qi:2011}, which uses the exponential map and the parallel transport, and the method from \cite{HuangGallivanAbsil:2015}, in which the so-called locking condition was introduced and discuss their key properties. The cautious Riemannian BFGS method from \cite{HuangAbsilGallivan:2018}, which allows more freedom in the choice of the stepsize strategy and avoids convexity assumptions for proving global convergence, is presented in \cref{Section4.5} and the limited-memory Riemannian BFGS method from \cite{HuangGallivanAbsil:2015} is detailed discussed in \cref{Section4.6}. \\
We explain in \cref{Section5.1} the approach of the RBFGS method implemented in \lstinline!Manopt.jl! (available at \url{https://manoptjl.org}, \cite{Bergmann:2019}) and we compare in \cref{Section5.2.1} its performance with the methods from \cite{Qi:2011}. In \cref{Section5.2.2} the performance of a cautious limited-memory RBFGS method, also implemented in \lstinline!Manopt.jl!, is compared with results from \cite{HuangGallivanAbsil:2015}. \\
Finally, conclusions are drawn and an outlook for the future is given in \cref{Chapter6}.